---
layout: page
title: Projects
---

## Articles:

* [Understanding GANs: MNIST case study.](https://medium.com/@pusavi17/understanding-gans-mnist-case-study-e3c9ad4ae3a7?source=friends_link&sk=4ede069c6dbc9b7509dc48b31e8ecbec)
  * In this article I explain how GANs work and help gain some intuition. One can also find the code [here](https://github.com/VictorSP17/Simple_GAN_MNIST).
  * Article published in Towards Data Science.
  
* [Training and visualization of feedforward neural networks.](https://github.com/VictorSP17/ANN_Feature_Visualization)
  * In this notebook you can find a very nice way to understand what neural networks are learning using different techniques.
  * We did this as a project for the EPFL class "Artificial Neural Networks".
  
* [Analysis of state-of-the-art deep generative models for images.](https://VictorSP17.github.io/website/documents/TFG_Victor_Salvia.pdf)
  * This is my bachelor thesis.
  * **ABSTRACT:** In this work we will try to break down the fundamentals of deep generative models for image generation. For the sake of simplicity and understanding we will be using the MNIST dataset, which can be easily trained and understood. The algorithms that we will be explaining and comparing are an autoregressive model, a flow-based model, a variational autoencoder, and a generative adversarial network. Within each of these categories, we have chosen simple algorithms for the sake of clarity as well. Keep in mind that this is a wide but introductory work to the area of image generation. However, these algorithms were certainly state-of the-art around 2016.
